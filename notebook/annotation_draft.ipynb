{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys, os\n",
    "sys.path.append(\"/Users/guillaumelaunay/work/DVL/python3/pyproteinsExt/src\")\n",
    "sys.path.append(\"/Users/guillaumelaunay/work/DVL/python3/pyproteins/src\")\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip, io\n",
    "import urllib.request\n",
    "\n",
    "def mFastaParseZip(inputFile):\n",
    "    data = None\n",
    "    with io.TextIOWrapper(gzip.open(inputFile, 'r')) as f:\n",
    "        data = mFastaParseStream(f)\n",
    "    return data\n",
    "\n",
    "def mFastaParseUrl(url):\n",
    "    fp = urllib.request.urlopen(url)\n",
    "    mybytes = fp.read()\n",
    "    #mFastaParseStream(fp)\n",
    "    mystr = mybytes.decode(\"utf8\")\n",
    "    fp.close()\n",
    "    data = mFastaParseStream(mystr.split('\\n'))\n",
    "    \n",
    "#    print(mystr)\n",
    "    return data\n",
    "\n",
    "def mFastaParseStream(stream):\n",
    "    \n",
    "    data = {}    \n",
    "    headPtr = ''\n",
    "    for line in stream:\n",
    "        #print (line)\n",
    "        if line == '':\n",
    "            continue\n",
    "        s = line.replace('\\n','')\n",
    "        if s.startswith('>'):\n",
    "            headPtr = s.split()[0][1:]\n",
    "            \n",
    "            if headPtr in data:\n",
    "                raise ValueError('Smtg wrong')\n",
    "            data[headPtr] = {'header': s, 'sequence' : '' }\n",
    "            \n",
    "            continue\n",
    "        data[headPtr]['sequence'] += s\n",
    "    return data\n",
    "\n",
    "#mFastaParseUrl('http://www.uniprot.org/uniprot/S4Z6V5.fasta')\n",
    "#data = mFastaParse('/Volumes/arwen/home/ygestin/prositetask-backup/alignTrembl/bibl/Trembl_47/Trembl_47.fasta.gz')\n",
    "#test=None\n",
    "#with open('/Volumes/arwen/mobi/group/NOX_GL/work/uniprot_trembl_v11/hmmsearch.fasta', 'r') as f:\n",
    "#    test = mFastaParseStream(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def num(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except ValueError:\n",
    "        return float(s)\n",
    "    \n",
    "    \n",
    "reTMH = re.compile('^(\\# ){0,1}([\\S]+)[\\s]+([\\S].*)[\\s]+([\\d\\.]+)$')\n",
    "def loadTMHMM(lDir):\n",
    "    \n",
    "    fastaContainer = None\n",
    "    with open( lDir+ '/hmmsearch.fasta', 'r') as f:\n",
    "        fastaContainer = mFastaParseStream(f)\n",
    "    \n",
    "    file = lDir+ '/tmhmm.out'\n",
    "    data = {}\n",
    "    with open(file, 'r') as f:\n",
    "        for l in f:\n",
    "            m = reTMH.search(l)\n",
    "            if m:\n",
    "                _id = m.groups()[1] \n",
    "                if _id not in data:\n",
    "                    if _id not in fastaContainer:\n",
    "                        raise ValueError(\"Misisng fasta for tmhmm prediction\")\n",
    "                    data[_id] = {'helix':[], 'fasta' : fastaContainer[_id]}\n",
    "                \n",
    "                if not m.groups()[2].startswith('TMHMM2'):\n",
    "                    data[_id][re.sub('[\\s]*:[\\s]*$', '',m.groups()[2])] = num(m.groups()[3])\n",
    "                    continue\n",
    "                \n",
    "                helixCoor = { 'volume' : None, 'start' : None, 'stop' : None }\n",
    "                #print (m.groups()[2])\n",
    "                m2 = m.groups()[2].split('\\t')\n",
    "                if not m2:\n",
    "                    raise ValueError('could not parse helix line')\n",
    "                helixCoor['volume'] = m2[1]\n",
    "                helixCoor['start'] = num(m2[2].replace(' ', ''))\n",
    "                helixCoor['stop'] = num(m.groups()[3])\n",
    "\n",
    "                data[_id]['helix'].append(helixCoor)\n",
    "                \n",
    "                \n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "            \n",
    "#d = loadTMHMM('/Volumes/arwen/home/ygestin/prositetask-backup/alignTrembl/bibl/Trembl_47')\n",
    "d = loadTMHMM('/Volumes/arwen/mobi/group/NOX_GL/work_sample/uniprot_trembl_v11')\n",
    "\n",
    "#for datum in d:\n",
    "#    l = datum.split('|')\n",
    "#    if d[datum]['Number of predicted TMHs'] >= 2:\n",
    "#        print ('loading ' + datum)\n",
    "#        endPoint = 'http://www.uniprot.org/uniprot/' + l[1] + '.fasta'\n",
    "#        d[datum]['fasta'] = mFastaParseUrl(endPoint)\n",
    "    \n",
    "    #print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing all data files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing HMMR data\n",
    "NB: There are stdout of 3 consecutive hmmr calls\n",
    "\n",
    "All in a single **data** container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyproteinsExt.hmmrContainer as hm\n",
    "import glob\n",
    "dataDir=glob.glob('/Volumes/arwen/home/ygestin/prositetask-backup/alignTrembl/bibl/Trembl_*')\n",
    "\n",
    "data = hm.parse(inputFile=dataDir[0] + '/align-all.txt')\n",
    "for iDir in dataDir[1:]:\n",
    "    print(iDir)\n",
    "    data += hm.parse(inputFile=iDir + '/align-all.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyproteinsExt.hmmrContainer as hm\n",
    "import glob\n",
    "dataDir=glob.glob('/Volumes/arwen/mobi/group/NOX_GL/work/uniprot_trembl_v*')\n",
    "\n",
    "data = hm.parse(inputFile=dataDir[0] + '/hmmsearch.out')\n",
    "for iDir in dataDir[1:]:\n",
    "    print(iDir)\n",
    "    data += hm.parse(inputFile=iDir + '/hmmsearch.out')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading TMHMM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTMHMM = {}\n",
    "for lDir in dataDir:\n",
    "    d = loadTMHMM(lDir)\n",
    "    if set( dataTHMM.keys() ) & set( d.keys() ):\n",
    "        print('doublons')\n",
    "    dataTMHMM.update(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    if d not in dataTMHMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform a PFAM domain indexed data structure in a protein indexed data structure\n",
    "Then filter out the protein that feature the 3 domains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = data.T()\n",
    "D = {}\n",
    "for protein in T:\n",
    "    if len(T[protein]) == 3:\n",
    "           D[protein] = T[protein]\n",
    "len(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Report some numbers on domain occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "l = [ list(data.T()[protein]) for protein in data.T()]\n",
    "ids = set([item for sublist in l for item in sublist])\n",
    "# order alphabeticall and convert to string\n",
    "# gives uniq occurence\n",
    "# then count\n",
    "#set(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = hm.parse(inputFile='/Volumes/arwen/home/ygestin/prositetask-backup/alignTrembl/bibl/Trembl_109/align-all.txt')\n",
    "t = dt.T()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "u['tr|W8AZ77|W8AZ77_CERCA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cluster His in TMH by pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MotifNadph = 'G[ISVL]G[VIAF][TAS][PYTA]'\n",
    "MotifFad = 'H[PSA]F[TS][LIMV]'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
