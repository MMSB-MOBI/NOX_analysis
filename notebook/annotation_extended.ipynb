{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annotation of the extended set consist in the reading and merging of HMMR scan and mulitfasta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys, os\n",
    "sys.path.append(\"/Users/guillaumelaunay/work/DVL/python3/pyproteinsExt/src\")\n",
    "sys.path.append(\"/Users/guillaumelaunay/work/DVL/python3/pyproteins/src\")\n",
    "%load_ext autoreload\n",
    "## Plain fasta utility functions\n",
    "\n",
    "import gzip, io\n",
    "import urllib.request\n",
    "\n",
    "def mFastaParseZip(inputFile):\n",
    "    data = None\n",
    "    with io.TextIOWrapper(gzip.open(inputFile, 'r')) as f:\n",
    "        data = mFastaParseStream(f)\n",
    "    return data\n",
    "\n",
    "def mFastaParseUrl(url):\n",
    "    fp = urllib.request.urlopen(url)\n",
    "    mybytes = fp.read()\n",
    "    #mFastaParseStream(fp)\n",
    "    mystr = mybytes.decode(\"utf8\")\n",
    "    fp.close()\n",
    "    data = mFastaParseStream(mystr.split('\\n'))\n",
    "    \n",
    "#    print(mystr)\n",
    "    return data\n",
    "\n",
    "def mFastaParseStream(stream):\n",
    "    \n",
    "    data = {}    \n",
    "    headPtr = ''\n",
    "    for line in stream:\n",
    "        #print (line)\n",
    "        if line == '':\n",
    "            continue\n",
    "        s = line.replace('\\n','')\n",
    "        if s.startswith('>'):\n",
    "            headPtr = s.split()[0][1:]\n",
    "            \n",
    "            if headPtr in data:\n",
    "                raise ValueError('Smtg wrong')\n",
    "            data[headPtr] = {'header': s, 'sequence' : '' }\n",
    "            \n",
    "            continue\n",
    "        data[headPtr]['sequence'] += s\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read-in hmmr scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3274 proteins to reannotate\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "import pyproteinsExt.hmmrContainerFactory as hm\n",
    "\n",
    "mainContainer = {}\n",
    "\n",
    "fileName=\"/Volumes/arwen/mobi/group/NOX_GL/extendedSet/NOX_noEukaryota_PB_NR_hmmscan.out\"\n",
    "hscan = hm.parse(inputFile=fileName)\n",
    "print( len(hscan.T()), 'proteins to reannotate' )\n",
    "\n",
    "for e in hscan.T():\n",
    "    if e in mainContainer:\n",
    "        raise ValueError(\"Known id \", e)\n",
    "        \n",
    "    mainContainer[e] = { 'hmmr' :  hscan.T()[e], 'tmhmm' : { 'fasta' : None } }b\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read-in corresponding mfasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3274 available fasta entries\n"
     ]
    }
   ],
   "source": [
    "fastaContainer = None\n",
    "with open('/Volumes/arwen/mobi/group/NOX_GL/extendedSet/NOX_noEukaryota_PB_NR.fasta', 'r') as f:\n",
    "    fastaContainer = mFastaParseStream(f)\n",
    "print(len(list(fastaContainer.keys())), 'available fasta entries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _id in mainContainer:\n",
    "    if _id not in fastaContainer:\n",
    "        raise ValueError(_id, 'missing in fasta container')\n",
    "    mainContainer[_id]['tmhmm']['fasta'] = fastaContainer[_id]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract TaxonID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def getTaxID(datum):\n",
    "    reTaxID = re.compile('OX=([\\d]+)')\n",
    "    m = reTaxID.search(datum['tmhmm']['fasta']['header'])\n",
    "    if not m:\n",
    "        raise ValueError('Cant parse taxid from', datum['tmhmm']['fasta']['header'])\n",
    "    datum['taxid'] = m.groups()[0]\n",
    "    \n",
    "for _id in mainContainer:\n",
    "    getTaxID(mainContainer[_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect NCBI Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyproteinsExt.ontology\n",
    "taxonTree = pyproteinsExt.ontology.Ontology(file='/Users/guillaumelaunay/work/databases/ontology/ncbitaxon.owl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Flag Non Eukaryota phylum members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cant find Taxon node for 2083010\n",
      "Cant find Taxon node for 2109333\n",
      "Cant find Taxon node for 2109333\n",
      "Cant find Taxon node for 2083010\n",
      "Cant find Taxon node for 2083010\n",
      "Cant find Taxon node for 2116516\n",
      "Cant find Taxon node for 2116516\n",
      "Cant find Taxon node for 2107699\n",
      "Cant find Taxon node for 2107702\n",
      "Cant find Taxon node for 2107699\n",
      "Cant find Taxon node for 2107702\n",
      "Cant find Taxon node for 2126737\n",
      "Total number of bacterial sequences 2493 3274\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "u = 0\n",
    "for _id in mainContainer:\n",
    "    u += 1\n",
    "    taxid=mainContainer[_id]['taxid']\n",
    "    n = taxonTree.onto.search(iri='http://purl.obolibrary.org/obo/NCBITaxon_' + taxid)\n",
    "    if not n:\n",
    "        print ('Cant find Taxon node for', taxid)\n",
    "        mainContainer[_id]['isNoEukaryota'] = False  \n",
    "        continue\n",
    "\n",
    "    bool=True\n",
    "    for t in taxonTree._getLineage(n[0]):\n",
    "        if not t.label:\n",
    "            continue\n",
    "        if t.label[0] == 'Eukaryota':\n",
    "            bool=False\n",
    "            break\n",
    "    if bool:\n",
    "        cnt += 1\n",
    "    mainContainer[_id]['isNoEukaryota'] = bool      \n",
    "\n",
    "print(\"Total number of bacterial sequences\", cnt, u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deserialize the seed data set, to mark seed members in the extended data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restore a annotated container of  4915 elements\n",
      "472  seed elements marked among  2493  bacterial entries ( 3274  total )\n",
      "653  bacterial seed elements were found among  4915 entries\n"
     ]
    }
   ],
   "source": [
    "import pickle, time\n",
    "import time\n",
    "\n",
    "def save(data, tag=None):\n",
    "    saveDir=\"/Users/guillaumelaunay/work/projects/NOX\"\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    fTag = \"NOX_annotation_\" + tag + \"_\" if tag else \"NOX_annotation_\"\n",
    "    fSerialDump = fTag + timestr + \".pickle\"\n",
    "    with open(saveDir + '/' + fSerialDump, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print('data structure saved to', saveDir + '/' + fSerialDump)\n",
    "\n",
    "def load(fileName):\n",
    "    saveDir=\"/Users/guillaumelaunay/work/projects/NOX\"\n",
    "    d = pickle.load( open(saveDir + \"/\" + fileName, \"rb\" ) )\n",
    "    print(\"restore a annotated container of \", len(d), \"elements\")\n",
    "    return d\n",
    "\n",
    "seedContainer = load('NOX_annotation_fullPFAM_20180625-111432.pickle')\n",
    "\n",
    "nBact=0\n",
    "nSeed=0\n",
    "u=0\n",
    "for _id in mainContainer:\n",
    "    mainContainer[_id]['isSeed'] = False\n",
    "    if not mainContainer[_id]['isNoEukaryota']:\n",
    "        continue\n",
    "    nBact +=1\n",
    "    if _id not in seedContainer:\n",
    "        continue\n",
    "    if not seedContainer[_id]['isNoEukaryota']:\n",
    "        raise ValueError(\"Should be marked as non eukaryotic seed\")\n",
    "        \n",
    "    mainContainer[_id]['isSeed'] = True\n",
    "    nSeed += 1\n",
    "\n",
    "print(nSeed, ' seed elements marked among ', nBact, ' bacterial entries (', len(mainContainer), ' total )')\n",
    "u=0\n",
    "for _id in seedContainer:\n",
    "    if not 'isNoEukaryota' in seedContainer[_id]:\n",
    "        continue\n",
    "    if seedContainer[_id]['isNoEukaryota']:\n",
    "        u += 1\n",
    "print(u,' bacterial seed elements were found among ', len(seedContainer), 'entries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data structure saved to /Users/guillaumelaunay/work/projects/NOX/NOX_annotation_extendedSet_fullPFAM_20180628-162131.pickle\n"
     ]
    }
   ],
   "source": [
    "save(mainContainer,'extendedSet_fullPFAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181 ['tr|A0A2E3PFI0|A0A2E3PFI0_9RHOB', 'tr|S7UF45|S7UF45_9DELT', 'tr|A0A064C2Q2|A0A064C2Q2_STREE']\n"
     ]
    }
   ],
   "source": [
    "setSeed = set()\n",
    "for _id in seedContainer:\n",
    "    if 'isNoEukaryota' in seedContainer[_id]:\n",
    "        if seedContainer[_id]['isNoEukaryota']:\n",
    "            setSeed.add(_id)\n",
    "setExt = set([ _id for _id in mainContainer if mainContainer[_id]['isNoEukaryota'] ])\n",
    "\n",
    "missing = list(setSeed - setExt)\n",
    "print (len(missing),missing[:3])\n",
    "for m in missing:\n",
    "    if m in mainContainer:\n",
    "        print (m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
