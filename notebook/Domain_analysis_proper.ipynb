{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys, os\n",
    "sys.path.append(\"/Users/chilpert/Work/pyproteinsExt/src\")\n",
    "sys.path.append(\"/Users/chilpert/Work/pyproteins/src\")\n",
    "import pyproteinsExt \n",
    "import pyproteins\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load full Pfam annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "832\n"
     ]
    }
   ],
   "source": [
    "data=pickle.load(open(\"/Volumes/arwen/mobi/group/NOX_CH/pickle_saved/NOX_annotation_fullPFAM_20190411-174326.pickle\",\"rb\"))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parse data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(data): \n",
    "    '''Return dictionnary with domain as key and list of proteins that contains this domain as value'''\n",
    "    dic_domain={}\n",
    "    for protein in data :\n",
    "        for domain in data[protein]['hmmr']:\n",
    "            if domain in dic_domain:\n",
    "                dic_domain[domain].append(protein)\n",
    "            else:     \n",
    "                dic_domain[domain]=[protein]\n",
    "    return(dic_domain)       \n",
    "\n",
    "def simplify_data(data):\n",
    "    dic_protein={}\n",
    "    for protein in data : \n",
    "        dic_protein[protein]=list(data[protein]['hmmr'].keys())\n",
    "    return dic_protein    \n",
    "\n",
    "def assemble_domains_with_same_proteins(dic_domain):\n",
    "    dic_prot={}\n",
    "    for d in dic_domain:\n",
    "        dic_domain[d].sort()\n",
    "        prots=\",\".join(dic_domain[d])\n",
    "        if not prots in dic_prot: \n",
    "            dic_prot[prots]=set()\n",
    "        dic_prot[prots].add(d)\n",
    "    new_dic_domain={}    \n",
    "    for p in dic_prot: \n",
    "        doms=\",\".join(dic_prot[p])\n",
    "        new_dic_domain[doms]=p.split(\",\")\n",
    "    return new_dic_domain    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "dic_domain=parse_data(data)\n",
    "ordered_dic_domain=OrderedDict(sorted(dic_domain.items(),key=lambda kv: len(kv[1]),reverse=True))\n",
    "dic_protein=simplify_data(data)\n",
    "ordered_dic_protein=OrderedDict(sorted(dic_protein.items(),key=lambda kv: len(kv[1]),reverse=True))\n",
    "assemble_dic_domain=assemble_domains_with_same_proteins(dic_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create, browse and modify ete3 tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ete3 import NCBITaxa\n",
    "ncbi = NCBITaxa()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create tree from all taxids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_taxids=set([data[p]['taxid'] for p in data])\n",
    "all_tree=ncbi.get_topology(list(all_taxids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create dictionnary to complete ete3 tree  \n",
    "Dic_all_taxids :   \n",
    "    Key : taxid   \n",
    "    Value : dictionnary {'domains' : set of associated domains, 'proteins':set of associated proteins}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_domain=[\"NAD_binding_1\",\"FAD_binding_8\",\"Ferric_reduct\",\"FAD_binding_6\",\"NAD_binding_6\"]\n",
    "dic_all_taxids={}\n",
    "all_domains=set()\n",
    "for p in data:\n",
    "    taxid=data[p]['taxid']\n",
    "    domains=data[p]['hmmr']\n",
    "    domains_to_add=set()\n",
    "    for d in domains: \n",
    "        if d not in core_domain:\n",
    "            domains_to_add.add(d)\n",
    "        all_domains.add(d)\n",
    "    if taxid not in dic_all_taxids: \n",
    "        dic_all_taxids[taxid]={'domains':set(),'proteins':set()}\n",
    "    if not domains_to_add:\n",
    "        domains_to_add.add(\"Core domains\")\n",
    "    dic_all_taxids[taxid]['domains'].update(domains_to_add)    \n",
    "    dic_all_taxids[taxid]['proteins'].add(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Complete Tree object with list of domains and proteins for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list=[]\n",
    "for n in all_tree.traverse('postorder'):\n",
    "    node_list.append(n)\n",
    "    n.sameDomainNode=set()\n",
    "    #print(n.name,n.sci_name,n.rank)\n",
    "    if n.name in dic_all_taxids:\n",
    "        n.domains=dic_all_taxids[n.name]['domains']   \n",
    "        n.proteins=dic_all_taxids[n.name]['proteins']\n",
    "    else:\n",
    "        n.domains=set()\n",
    "        n.proteins=set()\n",
    "    if n.get_descendants():\n",
    "        for child in n.children: \n",
    "            n.domains.update(child.domains)    \n",
    "            n.proteins.update(child.proteins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Complete Tree object with list of nodes with same domains for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "for i in range(len(node_list)):\n",
    "    c+=1\n",
    "    for j in range(i+1,len(node_list)):\n",
    "        #print(i,j)\n",
    "        n1=node_list[i]\n",
    "        n2=node_list[j]\n",
    "        if len(n1.domains)==len(n2.domains):\n",
    "            if not n1.domains.difference(n2.domains):\n",
    "                n1.sameDomainNode.add(n2)\n",
    "                n2.sameDomainNode.add(n1)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create DomainGroup objects, that contains domains associated with proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "class DomainGroup: \n",
    "    def __init__(self,domains,proteins,data):\n",
    "        self.domains=domains\n",
    "        self.proteins=proteins\n",
    "        self.taxids=list(set([data[p][\"taxid\"] for p in self.proteins]))\n",
    "        \n",
    "    def compute_upper_node(self,all_tree):\n",
    "        if len(self.taxids)==1: \n",
    "            self.upper_node=all_tree.search_nodes(name=self.taxids[0])[0]\n",
    "        else:     \n",
    "            tree=ncbi.get_topology(self.taxids)\n",
    "            traverse_generator=tree.traverse()\n",
    "            self.upper_node=next(traverse_generator)\n",
    "        \n",
    "    def compute_mean_max_distance(self):\n",
    "        self.dists=[]\n",
    "        tree=ncbi.get_topology(self.taxids)\n",
    "        if len(self.taxids)==1: \n",
    "            self.mean_dist=0\n",
    "            self.max_dist=0\n",
    "            return \n",
    "        for i in range(len(self.taxids)): \n",
    "            for j in range(i+1,len(self.taxids)):\n",
    "                dist=tree.get_distance(self.taxids[i],self.taxids[j])\n",
    "                self.dists.append(dist)\n",
    "        self.mean_dist=mean(self.dists)\n",
    "        self.max_dist=max(self.dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_DomainGroup=set()\n",
    "for k in assemble_dic_domain:\n",
    "    d=DomainGroup(k.split(\",\"),assemble_dic_domain[k],data)\n",
    "    d.compute_upper_node(all_tree)\n",
    "    d.compute_mean_max_distance()\n",
    "    set_DomainGroup.add(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in set_DomainGroup: \n",
    "    n=all_tree.search_nodes(name=s.upper_node.name)[0]\n",
    "    percent_taxo=len(s.proteins)/len(n.proteins)*100\n",
    "    s.percent_taxo=percent_taxo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Save objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "strtime = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "domain_groups_saved=\"/Volumes/arwen/mobi/group/NOX_CH/pickle_saved/domain_groups_\"+strtime+\".pickle\"\n",
    "tree_saved=\"/Volumes/arwen/mobi/group/NOX_CH/pickle_saved/ete3_tree_\"+strtime+\".pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(set_DomainGroup,open(domain_groups_saved,\"wb\"))\n",
    "pickle.dump(all_tree,open(tree_saved,\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "setDomains=pickle.load(open('/Volumes/arwen/mobi/group/NOX_CH/pickle_saved/domain_groups_20190423-142117.pickle',\"rb\"))\n",
    "all_tree=pickle.load(open('/Volumes/arwen/mobi/group/NOX_CH/pickle_saved/ete3_tree_20190423-142117.pickle',\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Output names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_domains_output=\"/Volumes/arwen/mobi/group/NOX_CH/Domain/domains_stats.tsv\"\n",
    "assemble_domains_output=\"/Volumes/arwen/mobi/group/NOX_CH/Domain/assembled_domains_stats.tsv\"\n",
    "assemble_domains_by_prot_output=\"/Volumes/arwen/mobi/group/NOX_CH/Domain/assembled_domains_sort_by_prot_stats.tsv\"\n",
    "proteins_output=\"/Volumes/arwen/mobi/group/NOX_CH/Domain/proteins_stats.tsv\"\n",
    "by_species_order_prot_output=\"/Volumes/arwen/mobi/group/NOX_CH/Domain/by_species_prot_order.tsv\"\n",
    "by_species_order_dom_output=\"/Volumes/arwen/mobi/group/NOX_CH/Domain/by_species_dom_order.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_domains_output(set_domain_groups,domains_output): \n",
    "    o=open(domains_output,\"w\")\n",
    "    o.write(\"#Domain(s)\\tNumber of associated proteins\\tAssociated proteins\\tUpper node(taxid)\\tUpper node(taxname)\\tUpper node(taxrank)\\t% taxon\\tMean distance\\tMax distance\\n\")\n",
    "    c=0\n",
    "    for d in set_domain_groups:\n",
    "        o.write(\"%s\\t%d\\t%s\\t%s\\t%s\\t%s\\t%.5f\\t%.5f\\t%.5f\\n\" % (\",\".join(d.domains),len(d.proteins),\",\".join(d.proteins),d.upper_node.name,d.upper_node.sci_name,d.upper_node.rank,d.percent_taxo,d.mean_dist,d.max_dist))\n",
    "    o.close()  \n",
    "    \n",
    "def write_by_specie_output(output,dic_species): \n",
    "    o=open(output,\"w\")\n",
    "    o.write(\"#Species taxid\\tSpecies name\\tNumber of proteins\\tNumber of domains\\tProteins\\tDomains\\n\")\n",
    "    for sp in dic_species:\n",
    "        o.write(str(sp[0])+\"\\t\"+sp[1]+\"\\t\"+str(len(dic_species[sp]['proteins']))+\"\\t\"+str(len(dic_species[sp]['domains']))+\"\\t\"+\",\".join(dic_species[sp]['proteins'])+\"\\t\"+\",\".join(dic_species[sp]['domains'])+\"\\n\")\n",
    "    o.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_domain_setDomains=sorted(setDomains,key=lambda d: len(d.domains),reverse=True)\n",
    "ordered_protein_setDomains=sorted(setDomains,key=lambda d: len(d.proteins),reverse=True)\n",
    "\n",
    "write_domains_output(ordered_domain_setDomains,assemble_domains_output)\n",
    "write_domains_output(ordered_protein_setDomains,assemble_domains_by_prot_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=open(proteins_output,\"w\")\n",
    "o.write(\"#Protein\\tTaxid\\tTaxname\\tTaxrank\\tNumber of domains\\tDomains\\n\")\n",
    "for p in ordered_dic_protein: \n",
    "    o.write(p+\"\\t\"+dic_taxonomy[p]['taxid']+\"\\t\"+dic_taxonomy[p]['taxname']+\"\\t\"+dic_taxonomy[p]['taxrank']+\"\\t\"+str(len(ordered_dic_protein[p]))+\"\\t\"+\",\".join(ordered_dic_protein[p])+\"\\n\")\n",
    "o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tax_level(taxid,tax_level): \n",
    "    taxid=int(taxid)\n",
    "    rank=ncbi.get_rank([taxid])[taxid]\n",
    "    if rank == tax_level : \n",
    "        taxname=ncbi.get_taxid_translator([taxid])[taxid]\n",
    "        return(taxid,taxname)\n",
    "    else:\n",
    "        lineage=ncbi.get_lineage(taxid)\n",
    "        ranks=ncbi.get_rank(lineage)\n",
    "        specie=[taxid for taxid in ranks if ranks[taxid]==tax_level]\n",
    "        if specie : \n",
    "            taxname=ncbi.get_taxid_translator(specie)[specie[0]]\n",
    "            return(taxid,taxname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_taxonomy={}\n",
    "for p in data: \n",
    "    taxid=data[p]['taxid']\n",
    "    taxname=ncbi.get_taxid_translator([taxid])[int(taxid)]\n",
    "    taxrank=ncbi.get_rank([taxid])[int(taxid)]\n",
    "    dic_taxonomy[p]={'taxid':taxid,'taxname':taxname,'taxrank':taxrank}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_specie={}\n",
    "for p in dic_taxonomy: \n",
    "    specie=get_tax_level(dic_taxonomy[p]['taxid'],\"species\")\n",
    "    if specie: \n",
    "        if specie not in dic_specie : \n",
    "            dic_specie[specie]={'proteins':set(),'domains':set()}\n",
    "        dic_specie[specie]['proteins'].add(p)\n",
    "        dic_specie[specie]['domains'].update(dic_protein[p])  \n",
    "\n",
    "ordered_prot_dic_species=OrderedDict(sorted(dic_specie.items(),key=lambda kv: len(kv[1]['proteins']),reverse=True))\n",
    "ordered_domain_dic_species=OrderedDict(sorted(dic_specie.items(),key=lambda kv: len(kv[1]['domains']),reverse=True))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_by_specie_output(by_species_order_prot_output,ordered_prot_dic_species)\n",
    "write_by_specie_output(by_species_order_dom_output,ordered_domain_dic_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
