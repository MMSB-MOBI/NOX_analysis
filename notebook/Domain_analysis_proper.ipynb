{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys, os\n",
    "sys.path.append(\"/Users/chilpert/Work/pyproteinsExt/src\")\n",
    "sys.path.append(\"/Users/chilpert/Work/pyproteins/src\")\n",
    "import pyproteinsExt \n",
    "import pyproteins\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load full Pfam annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377\n"
     ]
    }
   ],
   "source": [
    "data=pickle.load(open(\"/Volumes/arwen/mobi/group/NOX_CH/pickle_saved/NOX_annotation_fullPFAM_20190426-112439.pickle\",\"rb\"))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parse data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(data): \n",
    "    '''Return dictionnary with domain as key and list of proteins that contains this domain as value'''\n",
    "    dic_domain={}\n",
    "    for protein in data :\n",
    "        for domain in data[protein]['hmmr']:\n",
    "            if domain in dic_domain:\n",
    "                dic_domain[domain].append(protein)\n",
    "            else:     \n",
    "                dic_domain[domain]=[protein]\n",
    "    return(dic_domain)       \n",
    "\n",
    "def simplify_data(data):\n",
    "    dic_protein={}\n",
    "    for protein in data : \n",
    "        dic_protein[protein]=list(data[protein]['hmmr'].keys())\n",
    "    return dic_protein    \n",
    "\n",
    "def assemble_domains_with_same_proteins(dic_domain):\n",
    "    dic_prot={}\n",
    "    for d in dic_domain:\n",
    "        dic_domain[d].sort()\n",
    "        prots=\",\".join(dic_domain[d])\n",
    "        if not prots in dic_prot: \n",
    "            dic_prot[prots]=set()\n",
    "        dic_prot[prots].add(d)\n",
    "    new_dic_domain={}    \n",
    "    for p in dic_prot: \n",
    "        doms=\",\".join(dic_prot[p])\n",
    "        new_dic_domain[doms]=p.split(\",\")\n",
    "    return new_dic_domain    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "dic_domain=parse_data(data)\n",
    "ordered_dic_domain=OrderedDict(sorted(dic_domain.items(),key=lambda kv: len(kv[1]),reverse=True))\n",
    "dic_protein=simplify_data(data)\n",
    "ordered_dic_protein=OrderedDict(sorted(dic_protein.items(),key=lambda kv: len(kv[1]),reverse=True))\n",
    "assemble_dic_domain=assemble_domains_with_same_proteins(dic_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create, browse and modify ete3 tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ete3 import NCBITaxa\n",
    "ncbi = NCBITaxa()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create tree from all taxids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_taxids=set([data[p]['taxid'] for p in data])\n",
    "all_tree=ncbi.get_topology(list(all_taxids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create dictionnary to complete ete3 tree  \n",
    "Dic_all_taxids :   \n",
    "    Key : taxid   \n",
    "    Value : dictionnary {'domains' : set of associated domains, 'proteins':set of associated proteins}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_domain=[\"NAD_binding_1\",\"FAD_binding_8\",\"Ferric_reduct\",\"FAD_binding_6\",\"NAD_binding_6\"]\n",
    "dic_all_taxids={}\n",
    "all_domains=set()\n",
    "for p in data:\n",
    "    taxid=data[p]['taxid']\n",
    "    domains=data[p]['hmmr']\n",
    "    domains_to_add=set()\n",
    "    for d in domains: \n",
    "        if d not in core_domain:\n",
    "            domains_to_add.add(d)\n",
    "        all_domains.add(d)\n",
    "    if taxid not in dic_all_taxids: \n",
    "        dic_all_taxids[taxid]={'domains':set(),'proteins':set()}\n",
    "    if not domains_to_add:\n",
    "        domains_to_add.add(\"Core domains\")\n",
    "    dic_all_taxids[taxid]['domains'].update(domains_to_add)    \n",
    "    dic_all_taxids[taxid]['proteins'].add(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Complete Tree object with list of domains and proteins for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list=[]\n",
    "for n in all_tree.traverse('postorder'):\n",
    "    node_list.append(n)\n",
    "    n.sameDomainNode=set()\n",
    "    #print(n.name,n.sci_name,n.rank)\n",
    "    if n.name in dic_all_taxids:\n",
    "        n.domains=dic_all_taxids[n.name]['domains']   \n",
    "        n.proteins=dic_all_taxids[n.name]['proteins']\n",
    "    else:\n",
    "        n.domains=set()\n",
    "        n.proteins=set()\n",
    "    if n.get_descendants():\n",
    "        for child in n.children: \n",
    "            n.domains.update(child.domains)    \n",
    "            n.proteins.update(child.proteins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Complete Tree object with list of nodes with same domains for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "for i in range(len(node_list)):\n",
    "    c+=1\n",
    "    for j in range(i+1,len(node_list)):\n",
    "        #print(i,j)\n",
    "        n1=node_list[i]\n",
    "        n2=node_list[j]\n",
    "        if len(n1.domains)==len(n2.domains):\n",
    "            if not n1.domains.difference(n2.domains):\n",
    "                n1.sameDomainNode.add(n2)\n",
    "                n2.sameDomainNode.add(n1)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create DomainGroup objects, that contains domains associated with proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "class DomainGroup: \n",
    "    def __init__(self,domains,proteins,data):\n",
    "        self.domains=domains\n",
    "        self.proteins=proteins\n",
    "        self.taxids=list(set([data[p][\"taxid\"] for p in self.proteins]))\n",
    "        \n",
    "    def compute_upper_node(self,all_tree):\n",
    "        if len(self.taxids)==1: \n",
    "            self.upper_node=all_tree.search_nodes(name=self.taxids[0])[0]\n",
    "        else:     \n",
    "            tree=ncbi.get_topology(self.taxids)\n",
    "            traverse_generator=tree.traverse()\n",
    "            self.upper_node=next(traverse_generator)\n",
    "        \n",
    "    def compute_mean_max_distance(self):\n",
    "        self.dists=[]\n",
    "        tree=ncbi.get_topology(self.taxids)\n",
    "        if len(self.taxids)==1: \n",
    "            self.mean_dist=0\n",
    "            self.max_dist=0\n",
    "            return \n",
    "        for i in range(len(self.taxids)): \n",
    "            for j in range(i+1,len(self.taxids)):\n",
    "                dist=tree.get_distance(self.taxids[i],self.taxids[j])\n",
    "                self.dists.append(dist)\n",
    "        self.mean_dist=mean(self.dists)\n",
    "        self.max_dist=max(self.dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute distance and upper_node for each group of domains.  \n",
    "Mean distance is the mean distance between each pair of proteins. Max distance is the maximum distance among each pair of proteins. Upper node is the lowest node that gather all proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_DomainGroup=set()\n",
    "for k in assemble_dic_domain:\n",
    "    d=DomainGroup(k.split(\",\"),assemble_dic_domain[k],data)\n",
    "    d.compute_upper_node(all_tree)\n",
    "    d.compute_mean_max_distance()\n",
    "    set_DomainGroup.add(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute percentage taxonomy.  \n",
    "It's the percentage of proteins at this taxonomic level that contains the domains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in set_DomainGroup: \n",
    "    n=all_tree.search_nodes(name=s.upper_node.name)[0]\n",
    "    percent_taxo=len(s.proteins)/len(n.proteins)*100\n",
    "    s.percent_taxo=percent_taxo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Save objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "strtime = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "domain_groups_saved=\"/Volumes/arwen/mobi/group/NOX_CH/pickle_saved/domain_groups_\"+strtime+\".pickle\"\n",
    "tree_saved=\"/Volumes/arwen/mobi/group/NOX_CH/pickle_saved/ete3_tree_\"+strtime+\".pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(set_DomainGroup,open(domain_groups_saved,\"wb\"))\n",
    "pickle.dump(all_tree,open(tree_saved,\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "setDomains=pickle.load(open('/Volumes/arwen/mobi/group/NOX_CH/pickle_saved/domain_groups_20190426-113558.pickle',\"rb\"))\n",
    "all_tree=pickle.load(open('/Volumes/arwen/mobi/group/NOX_CH/pickle_saved/ete3_tree_20190426-113558.pickle',\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Output names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_domains_output=\"/Volumes/arwen/mobi/group/NOX_CH/Domain/domains_stats.tsv\"\n",
    "assemble_domains_output=\"/Volumes/arwen/mobi/group/NOX_CH/Domain/assembled_domains_stats.tsv\"\n",
    "assemble_domains_by_prot_output=\"/Volumes/arwen/mobi/group/NOX_CH/Domain/assembled_domains_sort_by_prot_stats.tsv\"\n",
    "proteins_output=\"/Volumes/arwen/mobi/group/NOX_CH/Domain/proteins_stats.tsv\"\n",
    "by_species_order_prot_output=\"/Volumes/arwen/mobi/group/NOX_CH/Domain/by_species_prot_order.tsv\"\n",
    "by_species_order_dom_output=\"/Volumes/arwen/mobi/group/NOX_CH/Domain/by_species_dom_order.tsv\"\n",
    "by_genus_order_prot_output=\"/Volumes/arwen/mobi/group/NOX_CH/Domain/by_genus_prot_order.tsv\"\n",
    "by_genus_order_dom_output=\"/Volumes/arwen/mobi/group/NOX_CH/Domain/by_genus_dom_order.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_domains_output(set_domain_groups,domains_output): \n",
    "    o=open(domains_output,\"w\")\n",
    "    o.write(\"#Domain(s)\\tNumber of associated proteins\\tAssociated proteins\\tUpper node(taxid)\\tUpper node(taxname)\\tUpper node(taxrank)\\t% taxon\\tMean distance\\tMax distance\\n\")\n",
    "    c=0\n",
    "    for d in set_domain_groups:\n",
    "        o.write(\"%s\\t%d\\t%s\\t%s\\t%s\\t%s\\t%.5f\\t%.5f\\t%.5f\\n\" % (\",\".join(d.domains),len(d.proteins),\",\".join(d.proteins),d.upper_node.name,d.upper_node.sci_name,d.upper_node.rank,d.percent_taxo,d.mean_dist,d.max_dist))\n",
    "    o.close()  \n",
    "    \n",
    "def write_by_tax_level_output(output,dic_tax_level,tax_level): \n",
    "    o=open(output,\"w\")\n",
    "    o.write(\"#Taxo level\\tTaxo name\\tNumber of proteins\\tNumber of domains\\tProteins\\tDomains\\n\")\n",
    "    for tl in dic_tax_level:\n",
    "        o.write(tax_level+\"\\t\"+tl+\"\\t\"+str(len(dic_tax_level[tl]['proteins']))+\"\\t\"+str(len(dic_tax_level[tl]['domains']))+\"\\t\"+\",\".join(dic_tax_level[tl]['proteins'])+\"\\t\"+\",\".join(dic_tax_level[tl]['domains'])+\"\\n\")\n",
    "    o.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_domain_setDomains=sorted(setDomains,key=lambda d: len(d.domains),reverse=True)\n",
    "ordered_protein_setDomains=sorted(setDomains,key=lambda d: len(d.proteins),reverse=True)\n",
    "\n",
    "write_domains_output(ordered_domain_setDomains,assemble_domains_output)\n",
    "write_domains_output(ordered_protein_setDomains,assemble_domains_by_prot_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_taxonomy={}\n",
    "for p in data: \n",
    "    taxid=data[p]['taxid']\n",
    "    taxname=ncbi.get_taxid_translator([taxid])[int(taxid)]\n",
    "    taxrank=ncbi.get_rank([taxid])[int(taxid)]\n",
    "    dic_taxonomy[p]={'taxid':taxid,'taxname':taxname,'taxrank':taxrank}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=open(proteins_output,\"w\")\n",
    "o.write(\"#Protein\\tTaxid\\tTaxname\\tTaxrank\\tNumber of domains\\tDomains\\n\")\n",
    "for p in ordered_dic_protein: \n",
    "    o.write(p+\"\\t\"+dic_taxonomy[p]['taxid']+\"\\t\"+dic_taxonomy[p]['taxname']+\"\\t\"+dic_taxonomy[p]['taxrank']+\"\\t\"+str(len(ordered_dic_protein[p]))+\"\\t\"+\",\".join(ordered_dic_protein[p])+\"\\n\")\n",
    "o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tax_level(taxid,tax_level): \n",
    "    taxid=int(taxid)\n",
    "    rank=ncbi.get_rank([taxid])[taxid]\n",
    "    if rank == tax_level : \n",
    "        taxname=ncbi.get_taxid_translator([taxid])[taxid]\n",
    "        return(taxname)\n",
    "    else:\n",
    "        lineage=ncbi.get_lineage(taxid)\n",
    "        ranks=ncbi.get_rank(lineage)\n",
    "        specie=[taxid for taxid in ranks if ranks[taxid]==tax_level]\n",
    "        if specie : \n",
    "            taxname=ncbi.get_taxid_translator(specie)[specie[0]]\n",
    "            return(taxname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_dic_tax_level(tax_level,dic,prot,dic_prot):\n",
    "    if tax_level: \n",
    "        if tax_level not in dic: \n",
    "            dic[tax_level]={'proteins':set(),'domains':set()}\n",
    "        dic[tax_level]['proteins'].add(prot)\n",
    "        dic[tax_level]['domains'].update(dic_prot[prot])\n",
    "    return dic     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_specie={}\n",
    "dic_genus={}\n",
    "for p in dic_taxonomy: \n",
    "    specie=get_tax_level(dic_taxonomy[p]['taxid'],\"species\")\n",
    "    genus=get_tax_level(dic_taxonomy[p]['taxid'],\"genus\")\n",
    "    dic_genus=complete_dic_tax_level(genus,dic_genus,p,dic_protein)\n",
    "    if specie: \n",
    "        if specie not in dic_specie : \n",
    "            dic_specie[specie]={'proteins':set(),'domains':set()}\n",
    "        dic_specie[specie]['proteins'].add(p)\n",
    "        dic_specie[specie]['domains'].update(dic_protein[p])  \n",
    "\n",
    "ordered_prot_dic_species=OrderedDict(sorted(dic_specie.items(),key=lambda kv: len(kv[1]['proteins']),reverse=True))\n",
    "ordered_domain_dic_species=OrderedDict(sorted(dic_specie.items(),key=lambda kv: len(kv[1]['domains']),reverse=True))\n",
    "ordered_prot_dic_genus=OrderedDict(sorted(dic_genus.items(),key=lambda kv: len(kv[1]['proteins']),reverse=True))\n",
    "ordered_domain_dic_genus=OrderedDict(sorted(dic_genus.items(),key=lambda kv: len(kv[1]['domains']),reverse=True))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_by_tax_level_output(by_species_order_prot_output,ordered_prot_dic_species,\"species\")\n",
    "write_by_tax_level_output(by_species_order_dom_output,ordered_domain_dic_species,\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report same nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_browse=set()\n",
    "clusters_node=[]\n",
    "for n1 in all_tree.traverse(): \n",
    "    #print(\"N1\",n1.name,n1.sci_name)\n",
    "    if n1.name not in node_browse: \n",
    "        #print(\"BROWSE\")\n",
    "        set_nodes=set()\n",
    "        set_nodes.add(n1)\n",
    "        node_browse.add(n1.name)\n",
    "        for n2 in n1.sameDomainNode: \n",
    "            node_browse.add(n2.name)\n",
    "            #print(\"N2\",n2.name,n2.sci_name)\n",
    "            set_nodes.add(n2)\n",
    "        clusters_node.append(set_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "for clust in clusters_node: \n",
    "    if len(clust)>1: \n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301 clusters has been found. 36 are not singletons.\n"
     ]
    }
   ],
   "source": [
    "print(str(len(clusters_node))+\" clusters has been found. \"+str(c)+\" are not singletons.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* See at which level domains remain the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "browse=set()\n",
    "highest_conserve_nodes=set()\n",
    "for n in all_tree.traverse():\n",
    "    #print(n.name,n.sci_name,n.rank)\n",
    "    desc=set(n.get_descendants())\n",
    "    if n not in browse and desc and desc.issubset(n.sameDomainNode):\n",
    "        browse.update(desc)\n",
    "        highest_conserve_nodes.add(n)\n",
    "    browse.add(n)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(highest_conserve_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clusters=\"/Volumes/arwen/mobi/group/NOX_CH/Domain/all_cluster_nodes.tsv\"\n",
    "all_clusters_nodes_separated=\"/Volumes/arwen/mobi/group/NOX_CH/Domain/all_cluster_nodes_oneline_per_node.tsv\"\n",
    "all_clusters_no_singletons=\"/Volumes/arwen/mobi/group/NOX_CH/Domain/all_cluster_nodes_no_singletons.tsv\"\n",
    "all_clusters_no_singletons_nodes_separated=\"/Volumes/arwen/mobi/group/NOX_CH/Domain/all_cluster_nodes_no_singletons_oneline_per_node.tsv\"\n",
    "highest_conserve_nodes_out=\"/Volumes/arwen/mobi/group/NOX_CH/Domain/highest_conserve_nodes.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=open(all_clusters,\"w\")\n",
    "o2=open(all_clusters_no_singletons,\"w\")\n",
    "o.write(\"#Cluster\\tCluster size\\tNode taxid(s)\\tNode name(s)\\tNode rank(s)\\tNumber of domains\\tList of domains\\n\")\n",
    "clust_nb=0\n",
    "for clust in clusters_node : \n",
    "    clust_nb+=1\n",
    "    taxids=[n.name for n in clust]\n",
    "    names=[n.sci_name for n in clust]\n",
    "    ranks=[n.rank for n in clust]\n",
    "    domains=list(clust)[0].domains\n",
    "    o.write(\"%d\\t%d\\t%s\\t%s\\t%s\\t%d\\t%s\\n\" % (clust_nb,len(clust),\",\".join(taxids),\",\".join(names),\",\".join(ranks),len(domains),\",\".join(domains)))\n",
    "    if len(clust)>1: \n",
    "        o2.write(\"%d\\t%d\\t%s\\t%s\\t%s\\t%d\\t%s\\n\" % (clust_nb,len(clust),\",\".join(taxids),\",\".join(names),\",\".join(ranks),len(domains),\",\".join(domains)))\n",
    "o.close()    \n",
    "o2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=open(all_clusters_nodes_separated,\"w\")\n",
    "o2=open(all_clusters_no_singletons_nodes_separated,\"w\")\n",
    "clust_nb=0\n",
    "for clust in clusters_node : \n",
    "    clust_nb+=1\n",
    "    for n in clust :   \n",
    "        o.write(\"%d\\t%d\\t%s\\t%s\\t%s\\t%d\\t%s\\n\" % (clust_nb,len(clust),n.name,n.sci_name,n.rank,len(n.domains),\",\".join(n.domains)))\n",
    "    if len(clust)>1: \n",
    "        for n in clust : \n",
    "            o2.write(\"%d\\t%d\\t%s\\t%s\\t%s\\t%d\\t%s\\n\" % (clust_nb,len(clust),n.name,n.sci_name,n.rank,len(n.domains),\",\".join(n.domains)))\n",
    "o.close()    \n",
    "o2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=open(highest_conserve_nodes_out,\"w\")\n",
    "o.write(\"#Node taxid\\tNode name\\tNode rank\\tNumber of descendants\\tNumber of domains\\tDomains\\n\")\n",
    "for n in highest_conserve_nodes: \n",
    "    o.write(\"%s\\t%s\\t%s\\t%d\\t%d\\t%s\\n\" %(n.name,n.sci_name,n.rank,len(n.get_descendants()),len(n.domains),\",\".join(n.domains)))\n",
    "o.close()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
